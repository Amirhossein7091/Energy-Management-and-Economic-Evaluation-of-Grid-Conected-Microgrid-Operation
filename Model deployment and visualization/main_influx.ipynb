{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 'source ~/anaconda3/bin/activate root' in CLI\n",
    "# Run 'anaconda-navigator' in CLI\n",
    "# Open jupyter notebook\n",
    "# Run 'sudo service grafana-server start' in CLI\n",
    "# Go to 'http://localhost:3000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chongaih/anaconda3/lib/python3.7/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.2.post1 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import ess # self-built module for battery related function\n",
    "import preprocess # self-built module for preprocess related function\n",
    "import rl_model # self-built module for reinforcement learning related function\n",
    "import predictive_model # self-built module for prediction related function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import linprog\n",
    "\n",
    "import time\n",
    "import influxdb\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear programming optimization\n",
    "\n",
    "def optimize_linprog(pv, load, price, battery, num_timesteps):\n",
    "    \n",
    "    \"\"\"\n",
    "      1. x(t) - action at time t (within the range [-1, 1])\n",
    "         p(t) - real time price at time t\n",
    "         k - wear and tear cost of ESS\n",
    "         P - per unit rated power of ESS\n",
    "         E - per unit rated energy of ESS\n",
    "\n",
    "         objective: minimize the transactive cost across the next 24 hours\n",
    "                    min (x1*(p1+k) + x2*(p2+k) + ... + x24*(p24+k))\n",
    "         inequality constraint: operation limit - 0 <= x(t) * P / E + SOC(t) <= 1\n",
    "         bounds: upper and lower bound of action [-1, 1]\n",
    "         return: action of next 24 hours\n",
    "      2. the actual ESS output power = action * P\n",
    "      3. the SOC of ESS is updated after each hour and the linear programming optimization \n",
    "         is performed every hour with the updated data - model prediction control\n",
    "    \"\"\"\n",
    "\n",
    "    # coefficients of the linear objective function to be minimized\n",
    "    # coefficients is normalized with load and pv such that \n",
    "    # ESS will react normally if there is no PV\n",
    "    # ESS tend to store more PV when PV is much higher than load\n",
    "    c = (price + battery.wear_cost) * load / (load + pv) * battery.P_rated\n",
    "\n",
    "    # Inequality constraint - 0 <= x1 / E + SOC1 <= 1\n",
    "    Aup = np.ones((24, 24)) * battery.P_rated / battery.E_rated \n",
    "    Aup = np.tril(Aup)\n",
    "    Adown = np.flipud(Aup) * -1\n",
    "    A = np.concatenate((Aup, Adown), axis=0) \n",
    "    bup = np.ones((24,)) - battery.current_SOC\n",
    "    bdown = np.zeros((24,)) + battery.current_SOC - battery.target_SOC\n",
    "    b = np.concatenate((bup, bdown), axis=0)\n",
    "\n",
    "    # upper and lower bounds of the actions\n",
    "    bounds = []\n",
    "    for timestep in range(num_timesteps):\n",
    "        bounds.append((-1, 1))\n",
    "\n",
    "    # linear programming\n",
    "    res = linprog(c, A_ub=A, b_ub=b, bounds=bounds, method='revised simplex')\n",
    "    actions = res.x\n",
    "    \n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the monetary cost or benefit with/ without ESS/ battery\n",
    "# compute_benefit(x[:, 0:1], x[:, 1:2], x[:, 2:3], np.array([[0.]*len(x)]).transpose(), battery=None)\n",
    "\n",
    "def compute_benefit(pv_energy, load_energy, price, battery_energy, battery=None):\n",
    "    \n",
    "    # Reshape from 1d to 2d array and inverse_transform\n",
    "    if len(pv_energy.shape) == 1:\n",
    "        load_energy = np.reshape(load_energy, (1, -1))\n",
    "        pv_energy = np.reshape(pv_energy, (1, -1))\n",
    "        battery_energy = np.reshape(battery_energy, (1, -1))\n",
    "        price = np.reshape(price, (1, -1))\n",
    "    \n",
    "    load_energy = preprocess_tool.sc_energy.inverse_transform(load_energy) # pu to kWh\n",
    "    pv_energy = preprocess_tool.sc_energy.inverse_transform(pv_energy) # pu to kWh\n",
    "    battery_energy = preprocess_tool.sc_energy.inverse_transform(battery_energy) # pu to kWh\n",
    "    price = preprocess_tool.sc_price.inverse_transform(price) / 100 # pu to cents/kWh to $/kWh\n",
    "    \n",
    "    # Compute the transaction cost\n",
    "    net_energy = load_energy - pv_energy + battery_energy\n",
    "    cost_transaction = price * net_energy\n",
    "    \n",
    "    # Compute the wear and tear cost\n",
    "    if battery:\n",
    "        cost_wear = preprocess_tool.sc_price.inverse_transform(battery.wear_cost) * battery_energy\n",
    "    else:\n",
    "        cost_wear = 0\n",
    "            \n",
    "    return np.sum(cost_transaction + cost_wear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Declare preprocessing tool which contains the trained scalers and \n",
    "# functions for feature engineering and formatting for prediction\n",
    "preprocess_tool = preprocess.preprocess()\n",
    "\n",
    "# Declare the predictive model for load, price and pv\n",
    "model_load, model_price, model_pv = predictive_model.retrieve_model()\n",
    "\n",
    "# Declare the reinforcement learning model for action decision\n",
    "model_averse, model_seeking = rl_model.retrieve_model()\n",
    "\n",
    "# Declare battery used in respective cases\n",
    "# Solution solved using linear programming is continuous\n",
    "# Solution solved using reinforcement learing is discrete\n",
    "battery_lp_perfect = ess.battery_continuous()\n",
    "battery_lp_predict = ess.battery_continuous()\n",
    "battery_rl_averse = ess.battery_discrete()\n",
    "battery_rl_seeking = ess.battery_discrete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters used in prediction\n",
    "timesteps_in = 336 # data two week prior to the target\n",
    "timesteps_out = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influx\n",
    "\n",
    "1. The influx class DataFrameClient is used in the project. The DataFrameClient instantiates InfluxDBClient to connect to the backend. The DataFrameClient object holds information necessary to connect to InfluxDB. Requests can be made to InfluxDB directly through the client. The client reads and writes from pandas.\n",
    "\n",
    "2. https://influxdb-python.readthedocs.io/en/latest/api-documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class influx():\n",
    "    # Class variable\n",
    "    measurement1 = 'sensor'\n",
    "    measurement2 = 'result'\n",
    "    \n",
    "    # Initialize the influx client\n",
    "    def __init__(self, host='localhost', port=8086, \\\n",
    "                user=None, password=None,\\\n",
    "                db='energy'):\n",
    "        self.db = db\n",
    "        self.myclient = influxdb.DataFrameClient(host, port, user, password)\n",
    "        self.myclient.create_database(db)\n",
    "        self.myclient.switch_database(db)\n",
    "    \n",
    "    # Query from the database and the selected measurement\n",
    "    # precision in nano second and any input timestamp needs to be converted from s to ns\n",
    "    def query(self, query):\n",
    "        results = self.myclient.query(query=query, epoch='ns')\n",
    "        if results:\n",
    "            column = next(iter(results)) # measurements/table: dataframe, 0:[], 1:[]\n",
    "            df = results[column] # Return type is a dataframe\n",
    "            df.index = df.index.tz_convert(tz='Asia/Singapore') # Convert the timezone of the DateTimeindex\n",
    "            return df\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    # Write into the database and the selected measurement\n",
    "    # For bulk data, SeriesHelper will be much effective\n",
    "    def write(self, df, measurement, tag_columns=None, field_columns=None):\n",
    "        df.index = df.index.tz_localize(tz='Asia/Singapore') # Set to local timezone\n",
    "        # df must be a dataframe with DateTimeIndex\n",
    "        self.myclient.write_points(dataframe=df, measurement=measurement, \\\n",
    "                              tag_columns=tag_columns, field_columns=field_columns)\n",
    "    \n",
    "    # For demonstration, the database is dropped each end of demonstration\n",
    "    def reset(self):\n",
    "        self.myclient.drop_database(self.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TO BE REPLACED WITH REAL SENSORS' INPUTS \"\"\"\n",
    "\n",
    "# For simulation and demonstration purpose, the existing csv data is fed into the database.\n",
    "# In actual setting, this section should be replaced with real sensors' inputs\n",
    "class data_generator():\n",
    "    def __init__(self, sampling_interval=0.75):\n",
    "        self.idx_now = 0\n",
    "        self.sampling_interval = sampling_interval # seconds\n",
    "        self.df = pd.read_csv('Final Modified Data_Rev2.csv')\n",
    "        self.t_current = datetime.datetime.now() - datetime.timedelta(seconds=timesteps_in * sampling_interval)\n",
    "    \n",
    "    # Initialize the data in the database\n",
    "    def get_initial_data(self):\n",
    "        # The starting timing is set (Not real timing)\n",
    "        # The database updated each 5 seconds instead of each hour\n",
    "        times = [self.t_current + datetime.timedelta(seconds=self.sampling_interval * i) \\\n",
    "                for i in range(timesteps_in)]\n",
    "        times = pd.Series(times, name='time')\n",
    "\n",
    "        # Concatenate the time and the data from the dataframe\n",
    "        df_initial = pd.concat([self.df[self.idx_now:self.idx_now+timesteps_in], times], axis=1)\n",
    "        df_initial.set_index('time', inplace=True, drop=True)\n",
    "        \n",
    "        # Update to keep track inserted data\n",
    "        self.idx_now += timesteps_in\n",
    "        self.t_current = times.iloc[-1]\n",
    "        \n",
    "        return df_initial # Return a dataframe\n",
    "    \n",
    "    def get_subsequent_data(self):\n",
    "        \n",
    "        # The database updated each 5 seconds instead of each hour\n",
    "        times = [self.t_current + datetime.timedelta(seconds=self.sampling_interval)]\n",
    "        times = pd.Series(times, name='time')\n",
    "        \n",
    "        # Reset index as times idx will always start from 0\n",
    "        df_current = self.df[self.idx_now:self.idx_now+1].reset_index(inplace=False, drop=True)\n",
    "        \n",
    "        # Concatenate the time and the data from the dataframe\n",
    "        df_cont = pd.concat([df_current, times], axis=1)\n",
    "        df_cont.set_index('time', inplace=True, drop=True)\n",
    "                \n",
    "        # Update to keep track inserted data\n",
    "        self.idx_now += 1\n",
    "        self.t_current = times.iloc[-1]\n",
    "        \n",
    "        return df_cont # Return a dataframe        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/10/09 15:06:58 0.5 0.7 0.7\n",
      "2020/10/09 15:06:59 0.5 0.8999999999999999 0.8999999999999999\n",
      "2020/10/09 15:06:59 0.5000000000000002 0.94 0.94\n",
      "2020/10/09 15:07:00 0.7000000000000002 0.94 0.94\n",
      "2020/10/09 15:07:01 0.9000000000000001 0.94 0.94\n",
      "2020/10/09 15:07:02 0.7000000000000002 0.94 0.94\n",
      "2020/10/09 15:07:02 0.5000000000000002 0.94 0.94\n",
      "2020/10/09 15:07:03 0.5 0.94 0.94\n",
      "2020/10/09 15:07:04 0.5 0.94 0.94\n",
      "2020/10/09 15:07:05 0.5 0.94 0.94\n",
      "2020/10/09 15:07:05 0.5 0.94 0.94\n",
      "2020/10/09 15:07:06 0.6000000000000002 0.94 0.94\n",
      "2020/10/09 15:07:07 0.8000000000000002 0.94 0.94\n",
      "2020/10/09 15:07:08 1.0 0.94 0.94\n",
      "2020/10/09 15:07:08 1.0 0.94 0.94\n",
      "2020/10/09 15:07:09 1.0 0.94 0.94\n",
      "2020/10/09 15:07:10 0.9 0.86 0.86\n",
      "2020/10/09 15:07:11 0.7000000000000001 0.66 0.66\n",
      "2020/10/09 15:07:11 0.5000000000000001 0.5800000000000001 0.5800000000000001\n",
      "2020/10/09 15:07:12 0.5 0.5000000000000001 0.5000000000000001\n",
      "2020/10/09 15:07:13 0.5 0.5000000000000001 0.5000000000000001\n",
      "2020/10/09 15:07:14 0.5 0.6200000000000001 0.6200000000000001\n",
      "2020/10/09 15:07:14 0.5 0.8200000000000001 0.8200000000000001\n",
      "2020/10/09 15:07:15 0.5 0.9000000000000001 0.9000000000000001\n",
      "2020/10/09 15:07:16 0.5 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:17 0.5 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:17 0.5000000000000002 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:18 0.7000000000000002 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:19 0.8999999999999999 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:20 0.7 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:20 0.5 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:21 0.5 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:22 0.5 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:23 0.5 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:23 0.6000000000000002 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:24 0.8000000000000002 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:25 1.0 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:26 1.0 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:26 1.0 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:27 1.0 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:28 0.9 0.9400000000000002 0.9400000000000002\n",
      "2020/10/09 15:07:29 0.7000000000000001 0.7400000000000002 0.7400000000000002\n",
      "2020/10/09 15:07:29 0.5000000000000001 0.5400000000000003 0.5400000000000003\n",
      "2020/10/09 15:07:30 0.5 0.5400000000000003 0.5400000000000003\n",
      "2020/10/09 15:07:31 0.5 0.5400000000000003 0.5400000000000003\n",
      "2020/10/09 15:07:32 0.5 0.6600000000000003 0.6600000000000003\n",
      "2020/10/09 15:07:32 0.5 0.8600000000000002 0.8600000000000002\n",
      "2020/10/09 15:07:33 0.5 0.9400000000000003 0.9400000000000003\n",
      "2020/10/09 15:07:34 0.5 0.8600000000000003 0.8600000000000003\n",
      "2020/10/09 15:07:35 0.7 0.9400000000000004 0.9400000000000004\n",
      "2020/10/09 15:07:35 0.8999999999999999 0.9400000000000004 0.9400000000000004\n",
      "2020/10/09 15:07:36 1.0 0.9400000000000004 0.9400000000000004\n",
      "2020/10/09 15:07:37 1.0 0.9400000000000004 0.9400000000000004\n",
      "2020/10/09 15:07:38 0.8 0.9400000000000004 0.9400000000000004\n",
      "2020/10/09 15:07:38 0.6000000000000001 0.7800000000000005 0.7800000000000005\n",
      "2020/10/09 15:07:39 0.5 0.5800000000000005 0.5800000000000005\n",
      "2020/10/09 15:07:40 0.5 0.5800000000000005 0.5800000000000005\n",
      "2020/10/09 15:07:41 0.5 0.5800000000000005 0.5800000000000005\n",
      "2020/10/09 15:07:41 0.5 0.5400000000000005 0.5400000000000005\n",
      "2020/10/09 15:07:42 0.6000000000000002 0.5400000000000005 0.5400000000000005\n",
      "2020/10/09 15:07:43 0.8000000000000002 0.5400000000000005 0.5400000000000005\n",
      "2020/10/09 15:07:44 1.0 0.6600000000000005 0.6600000000000005\n",
      "2020/10/09 15:07:44 1.0 0.7400000000000005 0.7400000000000005\n",
      "2020/10/09 15:07:45 1.0 0.8200000000000006 0.8200000000000006\n",
      "2020/10/09 15:07:46 0.8 0.7400000000000007 0.7400000000000007\n",
      "2020/10/09 15:07:47 0.6000000000000001 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:07:47 0.5 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:07:48 0.5 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:07:49 0.5 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:07:50 0.5 0.7400000000000007 0.7400000000000007\n",
      "2020/10/09 15:07:50 0.5 0.9000000000000006 0.9000000000000006\n",
      "2020/10/09 15:07:51 0.5 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:52 0.5 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:53 0.7 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:53 0.8999999999999999 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:54 1.0 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:55 1.0 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:56 0.9 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:56 0.7000000000000001 0.9400000000000006 0.9400000000000006\n",
      "2020/10/09 15:07:57 0.7 0.7800000000000007 0.7800000000000007\n",
      "2020/10/09 15:07:58 0.7 0.5800000000000007 0.5800000000000007\n",
      "2020/10/09 15:07:59 0.5 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:07:59 0.5 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:00 0.7 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:01 0.8999999999999999 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:02 1.0 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:02 1.0 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:03 1.0 0.6600000000000007 0.6600000000000007\n",
      "2020/10/09 15:08:04 0.8 0.5800000000000007 0.5800000000000007\n",
      "2020/10/09 15:08:05 0.6000000000000001 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:05 0.5 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:06 0.5 0.5400000000000007 0.5400000000000007\n",
      "2020/10/09 15:08:07 0.5 0.6600000000000007 0.6600000000000007\n",
      "2020/10/09 15:08:08 0.5 0.8600000000000007 0.8600000000000007\n",
      "2020/10/09 15:08:08 0.5 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:09 0.5 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:10 0.5 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:11 0.6000000000000002 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:11 0.8000000000000002 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:12 1.0 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:13 1.0 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:14 0.9 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:14 0.7000000000000001 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:15 0.5000000000000001 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:16 0.5 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:17 0.5 0.9400000000000007 0.9400000000000007\n",
      "2020/10/09 15:08:17 0.5 0.8600000000000008 0.8600000000000008\n",
      "2020/10/09 15:08:18 0.6000000000000002 0.9400000000000008 0.9400000000000008\n",
      "2020/10/09 15:08:19 0.8000000000000002 0.8600000000000009 0.8600000000000009\n",
      "2020/10/09 15:08:20 1.0 0.940000000000001 0.940000000000001\n",
      "2020/10/09 15:08:20 1.0 0.940000000000001 0.940000000000001\n",
      "2020/10/09 15:08:21 1.0 0.860000000000001 0.860000000000001\n",
      "2020/10/09 15:08:22 0.8 0.9400000000000011 0.9400000000000011\n",
      "2020/10/09 15:08:23 0.6000000000000001 0.7400000000000011 0.7400000000000011\n",
      "2020/10/09 15:08:23 0.5 0.5400000000000011 0.5400000000000011\n",
      "2020/10/09 15:08:24 0.5 0.5400000000000011 0.5400000000000011\n",
      "2020/10/09 15:08:25 0.5 0.6600000000000011 0.6600000000000011\n",
      "2020/10/09 15:08:26 0.5 0.8600000000000011 0.8600000000000011\n",
      "2020/10/09 15:08:26 0.5 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:27 0.5 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:28 0.5 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:29 0.7 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:29 0.8999999999999999 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:30 1.0 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:31 1.0 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:32 0.8 0.9400000000000012 0.9400000000000012\n",
      "2020/10/09 15:08:32 0.6000000000000001 0.7800000000000011 0.7800000000000011\n",
      "2020/10/09 15:08:33 0.5 0.5800000000000012 0.5800000000000012\n",
      "2020/10/09 15:08:34 0.5 0.5800000000000012 0.5800000000000012\n",
      "2020/10/09 15:08:35 0.5 0.5400000000000011 0.5400000000000011\n",
      "2020/10/09 15:08:35 0.5 0.6600000000000011 0.6600000000000011\n",
      "2020/10/09 15:08:36 0.7 0.8200000000000012 0.8200000000000012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/10/09 15:08:37 0.8000000000000002 0.7000000000000012 0.7000000000000012\n",
      "2020/10/09 15:08:38 1.0 0.7000000000000012 0.7000000000000012\n",
      "2020/10/09 15:08:38 1.0 0.7000000000000012 0.7000000000000012\n",
      "2020/10/09 15:08:39 1.0 0.7000000000000012 0.7000000000000012\n",
      "2020/10/09 15:08:40 0.8 0.6200000000000012 0.6200000000000012\n",
      "2020/10/09 15:08:41 0.6000000000000001 0.5400000000000013 0.5400000000000013\n",
      "2020/10/09 15:08:41 0.5 0.5400000000000013 0.5400000000000013\n",
      "2020/10/09 15:08:42 0.5 0.5400000000000013 0.5400000000000013\n",
      "2020/10/09 15:08:43 0.5 0.5400000000000013 0.5400000000000013\n",
      "2020/10/09 15:08:44 0.5 0.6600000000000013 0.6600000000000013\n",
      "2020/10/09 15:08:44 0.5 0.8600000000000012 0.8600000000000012\n",
      "2020/10/09 15:08:45 0.5 0.9400000000000013 0.9400000000000013\n",
      "2020/10/09 15:08:46 0.5 0.9400000000000013 0.9400000000000013\n",
      "2020/10/09 15:08:47 0.7 0.9400000000000013 0.9400000000000013\n",
      "2020/10/09 15:08:47 0.8999999999999999 0.9400000000000013 0.9400000000000013\n",
      "2020/10/09 15:08:48 1.0 0.9400000000000013 0.9400000000000013\n",
      "2020/10/09 15:08:49 1.0 0.9400000000000013 0.9400000000000013\n",
      "2020/10/09 15:08:50 0.9 0.9400000000000013 0.9400000000000013\n",
      "2020/10/09 15:08:50 0.7000000000000001 0.7800000000000014 0.7800000000000014\n",
      "2020/10/09 15:08:51 0.5000000000000001 0.5800000000000014 0.5800000000000014\n",
      "2020/10/09 15:08:52 0.5 0.5400000000000014 0.5400000000000014\n",
      "2020/10/09 15:08:53 0.5 0.5400000000000014 0.5400000000000014\n",
      "2020/10/09 15:08:53 0.5 0.5400000000000014 0.5400000000000014\n",
      "2020/10/09 15:08:54 0.5 0.5400000000000014 0.5400000000000014\n",
      "2020/10/09 15:08:55 0.7 0.5400000000000014 0.5400000000000014\n",
      "2020/10/09 15:08:56 0.8000000000000002 0.6600000000000014 0.6600000000000014\n",
      "2020/10/09 15:08:56 1.0 0.7400000000000014 0.7400000000000014\n",
      "2020/10/09 15:08:57 1.0 0.8200000000000015 0.8200000000000015\n",
      "2020/10/09 15:08:58 0.8 0.7000000000000015 0.7000000000000015\n",
      "2020/10/09 15:08:59 0.6000000000000001 0.5000000000000016 0.5000000000000016\n",
      "2020/10/09 15:08:59 0.5 0.5000000000000016 0.5000000000000016\n",
      "2020/10/09 15:09:00 0.5 0.5000000000000016 0.5000000000000016\n",
      "2020/10/09 15:09:01 0.5 0.5000000000000016 0.5000000000000016\n",
      "2020/10/09 15:09:02 0.5 0.6200000000000015 0.6200000000000015\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d252aa9052f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mdf_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# Use tag columns when the timestamp is the same for different cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0minflux_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minflux_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasurement2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'case'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         print (datetime.datetime.strftime(generator.t_current, '%Y/%m/%d %H:%M:%S'), \\\n",
      "\u001b[0;32m<ipython-input-8-db45d0e76808>\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, df, measurement, tag_columns, field_columns)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# df must be a dataframe with DateTimeIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         self.myclient.write_points(dataframe=df, measurement=measurement, \\\n\u001b[0;32m---> 33\u001b[0;31m                               tag_columns=tag_columns, field_columns=field_columns)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# For demonstration, the database is dropped each end of demonstration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/influxdb/_dataframe_client.py\u001b[0m in \u001b[0;36mwrite_points\u001b[0;34m(self, dataframe, measurement, tags, tag_columns, field_columns, time_precision, database, retention_policy, batch_size, protocol, numeric_precision)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mfield_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfield_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mtime_precision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_precision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 numeric_precision=numeric_precision)\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             points = self._convert_dataframe_to_json(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/influxdb/_dataframe_client.py\u001b[0m in \u001b[0;36m_convert_dataframe_to_lines\u001b[0;34m(self, dataframe, measurement, field_columns, tag_columns, global_tags, time_precision, numeric_precision)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mtag_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             tag_df = self._stringify_dataframe(\n\u001b[0;32m--> 383\u001b[0;31m                 tag_df, numeric_precision, datatype='tag')\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# join prepended tags, leaving None values out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/influxdb/_dataframe_client.py\u001b[0m in \u001b[0;36m_stringify_dataframe\u001b[0;34m(dframe, numeric_precision, datatype)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# Find int and string columns for field-type data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mint_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mstring_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mselect_dtypes\u001b[0;34m(self, include, exclude)\u001b[0m\n\u001b[1;32m   3460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mextracted_dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3462\u001b[0;31m         \u001b[0munique_dtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_to_dict_of_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mget_dtypes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mdtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36mextract_array\u001b[0;34m(obj, extract_numpy)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m     \"\"\"\n\u001b[1;32m    339\u001b[0m     \u001b[0mExtract\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mExtensionArray\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSeries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize battery for different cases\n",
    "battery_lp_predict = ess.battery_continuous()\n",
    "battery_rl_averse = ess.battery_discrete()\n",
    "battery_rl_seeking = ess.battery_discrete()\n",
    "\n",
    "# Initialize influx DataFrameClient for query and write and generator for simulation\n",
    "influx_app = influx()\n",
    "generator = data_generator()\n",
    "\n",
    "# Initialize the data in the database\n",
    "influx_app.write(generator.get_initial_data(), influx_app.measurement1)\n",
    "\n",
    "try:\n",
    "    while generator.idx_now < len(generator.df):\n",
    "\n",
    "        influx_app.write(generator.get_subsequent_data(), influx_app.measurement1)\n",
    "\n",
    "        \"\"\"Retrive data from influx database\"\"\"\n",
    "        # Retrieve the past two weeks hourly data for LP with prediction and the past 24 hour data for RL\n",
    "        t_end = generator.t_current\n",
    "        t_end = datetime.datetime.timestamp(t_end) * 1000000000 # precision is in nanosecond\n",
    "        t_start = generator.t_current - datetime.timedelta(seconds=generator.sampling_interval * timesteps_in)\n",
    "        t_start = datetime.datetime.timestamp(t_start) * 1000000000\n",
    "        query = 'select * from {} where time >{:f} and time <={:f}'.format(influx_app.measurement1, t_start, t_end)\n",
    "        df = influx_app.query(query)\n",
    "\n",
    "        # Feature engineering and normalization\n",
    "        df = preprocess_tool.feature_engineering(df)\n",
    "        x = preprocess_tool.normalize_pv_load_price(df)\n",
    "\n",
    "        pv_current, load_current, price_current = np.array([x[-1, 0]]), np.array([x[-1, 1]]), np.array([x[-1, 2]])\n",
    "\n",
    "        \"\"\"WITHOUT ESS\"\"\"\n",
    "        cost_woess = compute_benefit(pv_current, load_current, price_current, np.array([0.])) \n",
    "\n",
    "        \"\"\"WITH ESS AND MODEL PREDICTIVE CONTROL (LINEAR PROGRAMMING WITH PREDICTED KNOWLEDGE)\"\"\"\n",
    "        # (336,) + (336, 40) --> (336, 41) --> (1, 336, 41)\n",
    "        x_pv = np.concatenate((np.expand_dims(x[:,0], axis=1), df.iloc[:, 12:].values), axis=-1)\n",
    "        x_pv = np.expand_dims(x_pv, axis=0)\n",
    "        x_load = np.concatenate((np.expand_dims(x[:,1], axis=1), df.iloc[:, 12:].values), axis=-1)\n",
    "        x_load = np.expand_dims(x_load, axis=0)\n",
    "        x_price = np.concatenate((np.expand_dims(x[:,2], axis=1), df.iloc[:, 12:].values), axis=-1)\n",
    "        x_price = np.expand_dims(x_price, axis=0)\n",
    "\n",
    "        # Predict the future 24 hour load, price and pv\n",
    "        load_pred = model_load.predict(x_load[:, :, :], False)\n",
    "        load_pred = np.array(load_pred[0])[0, :, 0]\n",
    "        price_pred = model_price.predict(x_price[:, :, :], False)\n",
    "        price_pred = np.array(price_pred[0])[0, :, 0]\n",
    "        pv_pred = model_pv.predict(x_pv[:, :, :])\n",
    "        pv_pred = pv_pred[0, :, 0]\n",
    "\n",
    "        # Update SOC and store SOC, cost & action\n",
    "        # Use actual pv, load, price for cost computation\n",
    "        action_predict = optimize_linprog(pv_pred, load_pred, price_pred, battery_lp_predict, timesteps_out)[0]\n",
    "        SOC_predict = battery_lp_predict.update_SOC(action_predict)\n",
    "        cost_wess_predict = compute_benefit(pv_current, load_current, price_current, \n",
    "                                            np.array([action_predict])*battery_lp_predict.P_rated, \n",
    "                                            battery_lp_predict)\n",
    "\n",
    "        \"\"\"WITH ESS AND REINFORCEMENT LEARNING (RISK AVERSE AND RISK SEEKING)\"\"\"\n",
    "        price_avg = np.mean(x[-timesteps_out-1:-1, 2])\n",
    "\n",
    "        # per unit pv, load, price, SOC, average price of past 24 hours - 2D array\n",
    "        state_averse = np.expand_dims(np.concatenate((pv_current, load_current, price_current, \\\n",
    "                                                      np.array([battery_rl_averse.current_SOC]), \\\n",
    "                                                      np.array([price_avg]))), axis=0)\n",
    "        state_seeking = np.expand_dims(np.concatenate((pv_current, load_current, price_current, \\\n",
    "                                                      np.array([battery_rl_seeking.current_SOC]), \\\n",
    "                                                      np.array([price_avg]))), axis=0)\n",
    "\n",
    "        # Discrete solution ranging from [-1, 1] with interval of 0.2\n",
    "        action_averse = battery_rl_averse.action_set[np.argmax(model_averse.predict(state_averse))]\n",
    "        action_seeking = battery_rl_seeking.action_set[np.argmax(model_averse.predict(state_seeking))]\n",
    "\n",
    "        # TO BE REPLACED WITH INFLUX/ SQL STORE DATA\n",
    "        # Update SOC and store SOC, cost & action\n",
    "        SOC_averse = battery_rl_averse.update_SOC(action_averse)\n",
    "        SOC_seeking = battery_rl_seeking.update_SOC(action_seeking)\n",
    "        cost_wess_averse = compute_benefit(pv_current, load_current, price_current, \n",
    "                                           np.array([action_averse])*battery_rl_averse.P_rated, \n",
    "                                           battery_rl_averse)\n",
    "        cost_wess_seeking = compute_benefit(pv_current, load_current, price_current, \n",
    "                                            np.array([action_seeking])*battery_rl_seeking.P_rated, \n",
    "                                            battery_rl_seeking)\n",
    "\n",
    "        \"\"\"Insert data into the database\"\"\"\n",
    "        df_result = pd.DataFrame({'cost ($)': [cost_woess, cost_wess_predict, cost_wess_averse, cost_wess_seeking],\n",
    "                                  'action': [0, action_predict, action_averse, action_seeking],\n",
    "                                  'soc': [0, SOC_predict, SOC_averse, SOC_seeking],\n",
    "                                  'case': ['WOESS', 'ESS_MPC', 'ESS_RLRA', 'ESS_RLRS'],\n",
    "                                  'time': [generator.t_current] * 4})\n",
    "        df_result.set_index('time', inplace=True, drop=True)\n",
    "        # Use tag columns when the timestamp is the same for different cases\n",
    "        influx_app.write(df=df_result, measurement=influx_app.measurement2, tag_columns=['case'])\n",
    "\n",
    "        print (datetime.datetime.strftime(generator.t_current, '%Y/%m/%d %H:%M:%S'), \\\n",
    "               SOC_predict, SOC_averse, SOC_seeking)\n",
    "        \n",
    "        # time.sleep(3600) # Only execute once every hour\n",
    "\n",
    "except Exception as e:\n",
    "    print (e)\n",
    "    \n",
    "finally:\n",
    "    influx_app.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
